{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooperative-mainland",
   "metadata": {
    "papermill": {
     "duration": 0.023173,
     "end_time": "2021-06-20T05:47:57.628557",
     "exception": false,
     "start_time": "2021-06-20T05:47:57.605384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-pixel",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:57.685431Z",
     "iopub.status.busy": "2021-06-20T05:47:57.684792Z",
     "iopub.status.idle": "2021-06-20T05:47:58.946474Z",
     "shell.execute_reply": "2021-06-20T05:47:58.947670Z",
     "shell.execute_reply.started": "2021-06-19T11:15:02.775288Z"
    },
    "papermill": {
     "duration": 1.297204,
     "end_time": "2021-06-20T05:47:58.948010",
     "exception": false,
     "start_time": "2021-06-20T05:47:57.650806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-wrestling",
   "metadata": {
    "papermill": {
     "duration": 0.031317,
     "end_time": "2021-06-20T05:47:59.015867",
     "exception": false,
     "start_time": "2021-06-20T05:47:58.984550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data\n",
    "Load the csv files and view some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "musical-command",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.081241Z",
     "iopub.status.busy": "2021-06-20T05:47:59.080296Z",
     "iopub.status.idle": "2021-06-20T05:47:59.082621Z",
     "shell.execute_reply": "2021-06-20T05:47:59.082980Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.413996Z"
    },
    "papermill": {
     "duration": 0.033877,
     "end_time": "2021-06-20T05:47:59.083129",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.049252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join('../input/gtsrb-german-traffic-sign/Train.csv')\n",
    "test_file = os.path.join('../input/gtsrb-german-traffic-sign/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ethical-allah",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.145856Z",
     "iopub.status.busy": "2021-06-20T05:47:59.144459Z",
     "iopub.status.idle": "2021-06-20T05:47:59.238200Z",
     "shell.execute_reply": "2021-06-20T05:47:59.237679Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.42886Z"
    },
    "papermill": {
     "duration": 0.133424,
     "end_time": "2021-06-20T05:47:59.238377",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.104953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_file)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-angel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.289622Z",
     "iopub.status.busy": "2021-06-20T05:47:59.289102Z",
     "iopub.status.idle": "2021-06-20T05:47:59.317647Z",
     "shell.execute_reply": "2021-06-20T05:47:59.318069Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.539372Z"
    },
    "papermill": {
     "duration": 0.056878,
     "end_time": "2021-06-20T05:47:59.318263",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.261385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(test_file)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seasonal-gardening",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.369678Z",
     "iopub.status.busy": "2021-06-20T05:47:59.368450Z",
     "iopub.status.idle": "2021-06-20T05:47:59.372123Z",
     "shell.execute_reply": "2021-06-20T05:47:59.372648Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.58063Z"
    },
    "papermill": {
     "duration": 0.031621,
     "end_time": "2021-06-20T05:47:59.372824",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.341203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train csv shape: (39209, 8) \n",
      "Test csv shape: (12630, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train csv shape: {df_train.shape} \\nTest csv shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-penalty",
   "metadata": {
    "papermill": {
     "duration": 0.022999,
     "end_time": "2021-06-20T05:47:59.420011",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.397012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data distribution\n",
    "Displaying a bar chart which shows the sample of class occurences within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abandoned-fancy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.474184Z",
     "iopub.status.busy": "2021-06-20T05:47:59.473383Z",
     "iopub.status.idle": "2021-06-20T05:47:59.672801Z",
     "shell.execute_reply": "2021-06-20T05:47:59.673396Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.59008Z"
    },
    "papermill": {
     "duration": 0.230224,
     "end_time": "2021-06-20T05:47:59.673552",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.443328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = df_train['ClassId'].nunique()\n",
    "x = df_train['ClassId'].value_counts()\n",
    "\n",
    "plt.bar(x=x.index.sort_values(), height=x, color='#0066ff')\n",
    "plt.title('Numbers of sample in each class', color='black')\n",
    "plt.xlabel(\"Classes\", color='black')\n",
    "plt.ylabel(\"Samples\", color='black')\n",
    "plt.tick_params(colors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-tiffany",
   "metadata": {
    "papermill": {
     "duration": 0.02415,
     "end_time": "2021-06-20T05:47:59.722366",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.698216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Dataset\n",
    "Create a custom dataset class with the proper methods for importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "honest-washington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.785093Z",
     "iopub.status.busy": "2021-06-20T05:47:59.784194Z",
     "iopub.status.idle": "2021-06-20T05:47:59.786254Z",
     "shell.execute_reply": "2021-06-20T05:47:59.786687Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.879633Z"
    },
    "papermill": {
     "duration": 0.039855,
     "end_time": "2021-06-20T05:47:59.786833",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.746978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, image_info, target_shape=(32, 32)):\n",
    "        self.target_height = target_shape[0]\n",
    "        self.target_width = target_shape[1]\n",
    "\n",
    "        # read data \n",
    "        self.images_path, self.labels, self.nSample = self.read_label_data(image_info)\n",
    "\n",
    "    def read_label_data(self, image_info):\n",
    "        # load labels data\n",
    "        images_path = []\n",
    "        labels = []\n",
    "        number_data = 0\n",
    "        \n",
    "        # read label data from csv file\n",
    "        image_data = pd.read_csv(image_info)\n",
    "        \n",
    "        for index, data in image_data.iterrows():\n",
    "            images_path.append('../input/gtsrb-german-traffic-sign/' + data['Path'])\n",
    "            labels.append(data['ClassId'])\n",
    "            number_data += 1\n",
    "        \n",
    "        return images_path, labels, number_data\n",
    "\n",
    "    def read_image(self, img_path):\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (self.target_width, self.target_height), cv2.INTER_CUBIC)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img = img / 255.0\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images_path[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = self.read_image(img_path)\n",
    "\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nSample\n",
    "\n",
    "    def visualize_random_images(self, nb_row=2, nb_col=3):\n",
    "        fig, axes = plt.subplots(nb_row,nb_col, figsize=(18, 18))\n",
    "\n",
    "        for i,ax in enumerate(axes.flat):\n",
    "            r = np.random.randint(self.nSample)\n",
    "            img = cv2.imread(self.images_path[r])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img)\n",
    "            ax.grid(False)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('Label: '+ str(self.labels[r]))\n",
    "\n",
    "\n",
    "class Collator(object):\n",
    "    def __call__(self, batch):\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            img, label = sample\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "        return torch.FloatTensor(images), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-nature",
   "metadata": {
    "papermill": {
     "duration": 0.023801,
     "end_time": "2021-06-20T05:47:59.836687",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.812886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exclusive-settle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:47:59.889812Z",
     "iopub.status.busy": "2021-06-20T05:47:59.888955Z",
     "iopub.status.idle": "2021-06-20T05:48:03.022763Z",
     "shell.execute_reply": "2021-06-20T05:48:03.022012Z",
     "shell.execute_reply.started": "2021-06-19T11:15:04.903597Z"
    },
    "papermill": {
     "duration": 3.162521,
     "end_time": "2021-06-20T05:48:03.022939",
     "exception": false,
     "start_time": "2021-06-20T05:47:59.860418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data: 39209 \n",
      "The number of classes: 43\n"
     ]
    }
   ],
   "source": [
    "dataset = GTSRBDataset(image_info='../input/gtsrb-german-traffic-sign/Train.csv', target_shape=(32, 32))\n",
    "nb_classes = len(np.unique(dataset.labels))\n",
    "print('The number of data: {} \\nThe number of classes: {}'.format(len(dataset), nb_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-pacific",
   "metadata": {
    "papermill": {
     "duration": 0.024364,
     "end_time": "2021-06-20T05:48:03.072542",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.048178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split train and val dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noticed-kenya",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:03.128339Z",
     "iopub.status.busy": "2021-06-20T05:48:03.127665Z",
     "iopub.status.idle": "2021-06-20T05:48:03.148442Z",
     "shell.execute_reply": "2021-06-20T05:48:03.147800Z",
     "shell.execute_reply.started": "2021-06-19T11:15:09.301757Z"
    },
    "papermill": {
     "duration": 0.052095,
     "end_time": "2021-06-20T05:48:03.148604",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.096509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data:  31367\n",
      "The number of val data:  7842\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.8\n",
    "n_train = int(len(dataset) * split_ratio)\n",
    "n_val = len(dataset) - n_train\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "print(\"The number of train data: \", len(train_dataset))\n",
    "print(\"The number of val data: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-pastor",
   "metadata": {
    "papermill": {
     "duration": 0.024639,
     "end_time": "2021-06-20T05:48:03.198799",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.174160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metropolitan-compact",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:03.256211Z",
     "iopub.status.busy": "2021-06-20T05:48:03.255479Z",
     "iopub.status.idle": "2021-06-20T05:48:03.258149Z",
     "shell.execute_reply": "2021-06-20T05:48:03.257742Z",
     "shell.execute_reply.started": "2021-06-19T11:15:09.336369Z"
    },
    "papermill": {
     "duration": 0.034168,
     "end_time": "2021-06-20T05:48:03.258266",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.224098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create se_block\n",
    "class SEBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels, internal_neurons):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1, bias=True)\n",
    "        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1, bias=True)\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))\n",
    "        x = self.down(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.up(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x.view(-1, self.input_channels, 1, 1)\n",
    "        \n",
    "        return inputs * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "level-corruption",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:03.332544Z",
     "iopub.status.busy": "2021-06-20T05:48:03.331688Z",
     "iopub.status.idle": "2021-06-20T05:48:03.334190Z",
     "shell.execute_reply": "2021-06-20T05:48:03.333681Z",
     "shell.execute_reply.started": "2021-06-19T11:15:09.349707Z"
    },
    "papermill": {
     "duration": 0.0517,
     "end_time": "2021-06-20T05:48:03.334304",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.282604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create repvgg_block\n",
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "    result = nn.Sequential()\n",
    "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
    "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
    "    return result\n",
    "\n",
    "class RepVGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n",
    "        super(RepVGGBlock, self).__init__()\n",
    "        self.deploy = deploy\n",
    "        self.groups = groups\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        assert kernel_size == 3\n",
    "        assert padding == 1\n",
    "\n",
    "        padding_11 = padding - kernel_size // 2\n",
    "\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
    "        else:\n",
    "            self.se = nn.Identity()\n",
    "\n",
    "        if deploy:\n",
    "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
    "\n",
    "        else:\n",
    "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
    "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
    "            # print('RepVGG Block, identity = ', self.rbr_identity)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n",
    "\n",
    "        if self.rbr_identity is None:\n",
    "            id_out = 0\n",
    "        else:\n",
    "            id_out = self.rbr_identity(inputs)\n",
    "\n",
    "        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
    "\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "\n",
    "        if isinstance(branch, nn.Sequential):\n",
    "            kernel = branch.conv.weight\n",
    "            running_mean = branch.bn.running_mean\n",
    "            running_var = branch.bn.running_var\n",
    "            gamma = branch.bn.weight\n",
    "            beta = branch.bn.bias\n",
    "            eps = branch.bn.eps\n",
    "        else:\n",
    "            assert isinstance(branch, nn.BatchNorm2d)\n",
    "            if not hasattr(self, 'id_tensor'):\n",
    "                input_dim = self.in_channels // self.groups\n",
    "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
    "                for i in range(self.in_channels):\n",
    "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
    "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
    "            kernel = self.id_tensor\n",
    "            running_mean = branch.running_mean\n",
    "            running_var = branch.running_var\n",
    "            gamma = branch.weight\n",
    "            beta = branch.bias\n",
    "            eps = branch.eps\n",
    "            \n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "    def switch_to_deploy(self):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n",
    "                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n",
    "                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n",
    "        self.rbr_reparam.weight.data = kernel\n",
    "        self.rbr_reparam.bias.data = bias\n",
    "        for para in self.parameters():\n",
    "            para.detach_()\n",
    "        self.__delattr__('rbr_dense')\n",
    "        self.__delattr__('rbr_1x1')\n",
    "        if hasattr(self, 'rbr_identity'):\n",
    "            self.__delattr__('rbr_identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tracked-clerk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:03.397107Z",
     "iopub.status.busy": "2021-06-20T05:48:03.396371Z",
     "iopub.status.idle": "2021-06-20T05:48:03.398893Z",
     "shell.execute_reply": "2021-06-20T05:48:03.398502Z",
     "shell.execute_reply.started": "2021-06-19T11:15:09.382822Z"
    },
    "papermill": {
     "duration": 0.040485,
     "end_time": "2021-06-20T05:48:03.399001",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.358516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create repvgg model\n",
    "class RepVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False):\n",
    "        super(RepVGG, self).__init__()\n",
    "\n",
    "        assert len(width_multiplier) == 4\n",
    "\n",
    "        self.deploy = deploy\n",
    "        self.override_groups_map = override_groups_map or dict()\n",
    "        self.use_se = use_se\n",
    "\n",
    "        assert 0 not in self.override_groups_map\n",
    "\n",
    "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
    "\n",
    "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_se=self.use_se)\n",
    "        self.cur_layer_idx = 1\n",
    "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
    "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
    "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
    "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
    "\n",
    "\n",
    "    def _make_stage(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
    "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
    "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n",
    "            self.in_planes = planes\n",
    "            self.cur_layer_idx += 1\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stage0(x)\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def create_RepVGG_A0(num_classes, deploy=False):\n",
    "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_classes, width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "informative-special",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:03.456971Z",
     "iopub.status.busy": "2021-06-20T05:48:03.456473Z",
     "iopub.status.idle": "2021-06-20T05:48:07.752611Z",
     "shell.execute_reply": "2021-06-20T05:48:07.752122Z",
     "shell.execute_reply.started": "2021-06-19T11:15:09.407101Z"
    },
    "papermill": {
     "duration": 4.329437,
     "end_time": "2021-06-20T05:48:07.752753",
     "exception": false,
     "start_time": "2021-06-20T05:48:03.423316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repvgg_model = create_RepVGG_A0(num_classes=nb_classes)\n",
    "repvgg_model = repvgg_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-tuesday",
   "metadata": {
    "papermill": {
     "duration": 0.024377,
     "end_time": "2021-06-20T05:48:07.802574",
     "exception": false,
     "start_time": "2021-06-20T05:48:07.778197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instrumental-watershed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:07.856343Z",
     "iopub.status.busy": "2021-06-20T05:48:07.855530Z",
     "iopub.status.idle": "2021-06-20T05:48:07.858227Z",
     "shell.execute_reply": "2021-06-20T05:48:07.857787Z",
     "shell.execute_reply.started": "2021-06-19T11:15:14.876219Z"
    },
    "papermill": {
     "duration": 0.031582,
     "end_time": "2021-06-20T05:48:07.858332",
     "exception": false,
     "start_time": "2021-06-20T05:48:07.826750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "valid_every = 2000\n",
    "print_every = 500\n",
    "lr = 0.001\n",
    "num_iters = 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-manual",
   "metadata": {
    "papermill": {
     "duration": 0.024105,
     "end_time": "2021-06-20T05:48:07.906905",
     "exception": false,
     "start_time": "2021-06-20T05:48:07.882800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create dataloader for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adult-holly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:07.963548Z",
     "iopub.status.busy": "2021-06-20T05:48:07.962368Z",
     "iopub.status.idle": "2021-06-20T05:48:08.015112Z",
     "shell.execute_reply": "2021-06-20T05:48:08.014651Z",
     "shell.execute_reply.started": "2021-06-19T11:15:14.88592Z"
    },
    "papermill": {
     "duration": 0.083527,
     "end_time": "2021-06-20T05:48:08.015240",
     "exception": false,
     "start_time": "2021-06-20T05:48:07.931713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "data_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-press",
   "metadata": {
    "papermill": {
     "duration": 0.028388,
     "end_time": "2021-06-20T05:48:08.071791",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.043403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aware-knife",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.142547Z",
     "iopub.status.busy": "2021-06-20T05:48:08.141616Z",
     "iopub.status.idle": "2021-06-20T05:48:08.143526Z",
     "shell.execute_reply": "2021-06-20T05:48:08.143968Z",
     "shell.execute_reply.started": "2021-06-19T11:15:14.960437Z"
    },
    "papermill": {
     "duration": 0.04367,
     "end_time": "2021-06-20T05:48:08.144134",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.100464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(repvgg_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-09)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=num_iters, pct_start=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-manufacturer",
   "metadata": {
    "papermill": {
     "duration": 0.02829,
     "end_time": "2021-06-20T05:48:08.201861",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.173571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "impressive-frequency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.266454Z",
     "iopub.status.busy": "2021-06-20T05:48:08.265555Z",
     "iopub.status.idle": "2021-06-20T05:48:08.268191Z",
     "shell.execute_reply": "2021-06-20T05:48:08.267706Z",
     "shell.execute_reply.started": "2021-06-19T11:15:14.980928Z"
    },
    "papermill": {
     "duration": 0.03756,
     "end_time": "2021-06-20T05:48:08.268310",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.230750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_to_device(images, gts):\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    gts = gts.to(device, non_blocking=True)\n",
    "    \n",
    "    return images, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sensitive-proceeding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.329713Z",
     "iopub.status.busy": "2021-06-20T05:48:08.328963Z",
     "iopub.status.idle": "2021-06-20T05:48:08.331465Z",
     "shell.execute_reply": "2021-06-20T05:48:08.332228Z",
     "shell.execute_reply.started": "2021-06-19T11:15:14.991327Z"
    },
    "papermill": {
     "duration": 0.035962,
     "end_time": "2021-06-20T05:48:08.332389",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.296427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_acc(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "meaningful-welsh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.398119Z",
     "iopub.status.busy": "2021-06-20T05:48:08.397215Z",
     "iopub.status.idle": "2021-06-20T05:48:08.399691Z",
     "shell.execute_reply": "2021-06-20T05:48:08.400150Z",
     "shell.execute_reply.started": "2021-06-19T11:15:15.004Z"
    },
    "papermill": {
     "duration": 0.03888,
     "end_time": "2021-06-20T05:48:08.400276",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.361396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    repvgg_model.eval()\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, gts = batch\n",
    "            images, gts = batch_to_device(images, gts)\n",
    "            outputs = repvgg_model(images)\n",
    "            loss = criterion(outputs, gts)\n",
    "            acc = cal_acc(outputs, gts)\n",
    "            \n",
    "            total_loss.append(loss.item())\n",
    "            total_acc.append(acc)\n",
    "            \n",
    "            del outputs\n",
    "            del loss\n",
    "            \n",
    "    val_loss = np.mean(total_loss)\n",
    "    val_acc = np.mean(total_acc)\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "short-iraqi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.464155Z",
     "iopub.status.busy": "2021-06-20T05:48:08.463319Z",
     "iopub.status.idle": "2021-06-20T05:48:08.466283Z",
     "shell.execute_reply": "2021-06-20T05:48:08.465590Z",
     "shell.execute_reply.started": "2021-06-19T11:15:15.018505Z"
    },
    "papermill": {
     "duration": 0.038166,
     "end_time": "2021-06-20T05:48:08.466429",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.428263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    # get the inputs\n",
    "    images, gts = batch\n",
    "    images, gts = batch_to_device(images, gts)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize + scheduler\n",
    "    outputs = repvgg_model(images)\n",
    "    loss = criterion(outputs, gts)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(repvgg_model.parameters(), 1) \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_item = loss.item()\n",
    "    \n",
    "    return loss_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "confused-implementation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T05:48:08.536432Z",
     "iopub.status.busy": "2021-06-20T05:48:08.534714Z",
     "iopub.status.idle": "2021-06-20T06:27:54.723677Z",
     "shell.execute_reply": "2021-06-20T06:27:54.724117Z",
     "shell.execute_reply.started": "2021-06-19T11:15:15.03294Z"
    },
    "papermill": {
     "duration": 2386.227983,
     "end_time": "2021-06-20T06:27:54.724309",
     "exception": false,
     "start_time": "2021-06-20T05:48:08.496326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 000500, train_loss: 1.9706\n",
      "step: 001000, train_loss: 0.3966\n",
      "step: 001500, train_loss: 0.1764\n",
      "step: 002000, train_loss: 0.0932\n",
      "==============================================================================\n",
      "val_loss: 0.1052, val_acc: 0.9739\n",
      "==============================================================================\n",
      "step: 002500, train_loss: 0.0694\n",
      "step: 003000, train_loss: 0.0652\n",
      "step: 003500, train_loss: 0.0249\n",
      "step: 004000, train_loss: 0.0232\n",
      "==============================================================================\n",
      "val_loss: 0.0541, val_acc: 0.9873\n",
      "==============================================================================\n",
      "step: 004500, train_loss: 0.0262\n",
      "step: 005000, train_loss: 0.0172\n",
      "step: 005500, train_loss: 0.0217\n",
      "step: 006000, train_loss: 0.0227\n",
      "==============================================================================\n",
      "val_loss: 0.0401, val_acc: 0.9917\n",
      "==============================================================================\n",
      "step: 006500, train_loss: 0.0372\n",
      "step: 007000, train_loss: 0.0166\n",
      "step: 007500, train_loss: 0.0130\n",
      "step: 008000, train_loss: 0.0114\n",
      "==============================================================================\n",
      "val_loss: 0.0379, val_acc: 0.9942\n",
      "==============================================================================\n",
      "step: 008500, train_loss: 0.0270\n",
      "step: 009000, train_loss: 0.0014\n",
      "step: 009500, train_loss: 0.0013\n",
      "step: 010000, train_loss: 0.0147\n",
      "==============================================================================\n",
      "val_loss: 0.0436, val_acc: 0.9941\n",
      "==============================================================================\n",
      "step: 010500, train_loss: 0.0027\n",
      "step: 011000, train_loss: 0.0113\n",
      "step: 011500, train_loss: 0.0009\n",
      "step: 012000, train_loss: 0.0108\n",
      "==============================================================================\n",
      "val_loss: 0.0433, val_acc: 0.9942\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "best_acc = 0\n",
    "global_step = 0\n",
    "weight_path = 'repvgg.pth.tar'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for i in range(num_iters):\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(train_loader)\n",
    "        batch = next(data_iter)\n",
    "        \n",
    "    global_step += 1\n",
    "    loss = train_step(batch)\n",
    "    total_loss += loss\n",
    "\n",
    "    if global_step % print_every == 0:\n",
    "        print('step: {:06d}, train_loss: {:.4f}'.format(global_step, total_loss / print_every))\n",
    "        total_loss = 0\n",
    "        \n",
    "    if global_step % valid_every == 0:\n",
    "        # validate \n",
    "        val_loss, val_acc = validate()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(repvgg_model.state_dict(), weight_path)\n",
    "            \n",
    "        print(\"==============================================================================\")\n",
    "        print(\"val_loss: {:.4f}, val_acc: {:.4f}\".format(val_loss, val_acc))\n",
    "        print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-rebel",
   "metadata": {
    "papermill": {
     "duration": 0.031667,
     "end_time": "2021-06-20T06:27:54.788203",
     "exception": false,
     "start_time": "2021-06-20T06:27:54.756536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convert the training-time models into inference-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "located-principal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T06:27:54.860918Z",
     "iopub.status.busy": "2021-06-20T06:27:54.860070Z",
     "iopub.status.idle": "2021-06-20T06:27:55.289050Z",
     "shell.execute_reply": "2021-06-20T06:27:55.288542Z",
     "shell.execute_reply.started": "2021-06-19T12:00:11.653015Z"
    },
    "papermill": {
     "duration": 0.469213,
     "end_time": "2021-06-20T06:27:55.289205",
     "exception": false,
     "start_time": "2021-06-20T06:27:54.819992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n",
    "    if do_copy:\n",
    "        model = copy.deepcopy(model)\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'switch_to_deploy'):\n",
    "            module.switch_to_deploy()\n",
    "    if save_path is not None:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "# weight path\n",
    "weight_path = 'repvgg.pth.tar'\n",
    "convert_weight_path = 'convert_weight_path.pth.tar'\n",
    "\n",
    "# create model\n",
    "repvgg_model = create_RepVGG_A0(num_classes=43)\n",
    "repvgg_model.load_state_dict(torch.load(weight_path, map_location=device), strict=False)\n",
    "\n",
    "# convert multi branch model to single branch model\n",
    "convert_model = repvgg_model_convert(repvgg_model, save_path=convert_weight_path)\n",
    "convert_model = convert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-departure",
   "metadata": {
    "papermill": {
     "duration": 0.031782,
     "end_time": "2021-06-20T06:27:55.353307",
     "exception": false,
     "start_time": "2021-06-20T06:27:55.321525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check model in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "arctic-railway",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T06:27:55.422931Z",
     "iopub.status.busy": "2021-06-20T06:27:55.421670Z",
     "iopub.status.idle": "2021-06-20T06:27:55.424071Z",
     "shell.execute_reply": "2021-06-20T06:27:55.424433Z",
     "shell.execute_reply.started": "2021-06-19T12:04:19.171743Z"
    },
    "papermill": {
     "duration": 0.039254,
     "end_time": "2021-06-20T06:27:55.424560",
     "exception": false,
     "start_time": "2021-06-20T06:27:55.385306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, images, device):\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fancy-yellow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T06:27:55.497987Z",
     "iopub.status.busy": "2021-06-20T06:27:55.497299Z",
     "iopub.status.idle": "2021-06-20T06:30:14.787706Z",
     "shell.execute_reply": "2021-06-20T06:30:14.788200Z",
     "shell.execute_reply.started": "2021-06-19T12:04:57.229073Z"
    },
    "papermill": {
     "duration": 139.331009,
     "end_time": "2021-06-20T06:30:14.788384",
     "exception": false,
     "start_time": "2021-06-20T06:27:55.457375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in test dataset:  94.9089469517023\n"
     ]
    }
   ],
   "source": [
    "# Number of image predict true\n",
    "lst_wrong_img = []\n",
    "tp = 0\n",
    "\n",
    "for index, data in df_test.iterrows():\n",
    "    img = cv2.imread('../input/gtsrb-german-traffic-sign/' + data['Path'])\n",
    "    \n",
    "    preprocess_img = cv2.resize(img, (32, 32), cv2.INTER_AREA)\n",
    "    preprocess_img = preprocess_img.transpose(2, 0, 1)\n",
    "    preprocess_img = preprocess_img / 255.0\n",
    "    preprocess_img = np.expand_dims(preprocess_img, axis=0)\n",
    "    preprocess_img = torch.FloatTensor(preprocess_img)\n",
    "    \n",
    "    output = predict(convert_model, preprocess_img, device)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    \n",
    "    if(int(output[0]) == data['ClassId']):\n",
    "        tp += 1\n",
    "    else:\n",
    "        lst_wrong_img.append([data['Path'], data['ClassId'], int(output[0])])\n",
    "\n",
    "df = pd.DataFrame(lst_wrong_img, columns = ['Path', 'ClassId', 'Predict'])\n",
    "df.to_csv('list_wrong_imgs.csv', index=False)\n",
    "\n",
    "print(\"Accuracy in test dataset: \", float(tp/df_test.shape[0])*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2545.358241,
   "end_time": "2021-06-20T06:30:16.569527",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-20T05:47:51.211286",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
